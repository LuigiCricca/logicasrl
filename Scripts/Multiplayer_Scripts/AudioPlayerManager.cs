using System.Collections;
using System.Collections.Generic;
using UnityEngine;
using Normal.Realtime;
using Normal.Realtime.Native;

public class AudioPlayerManager : AudioOutput
{
    private AudioClip _audioClip;
    AudioOutputStream audioStream;
    private int _systemSampleRate;
    // Start is called before the first frame update
    private void Awake()
    {
        _systemSampleRate = AudioSettings.outputSampleRate;
    }
    void OnEnable()
    {
        if (audioStream != null)
        {
            AudioSource audioSource = GetComponent<AudioSource>();
            if (audioSource != null)
            {
                if (!audioSource.isPlaying)
                    audioSource.Play();
            }
            else
            {
                Debug.LogError("Realtime: AudioOutput has audio output stream, but no AudioSource. Was it destroyed on accident?");
            }
        }
    }
    

    

    public void StartWithAudioOutputStreams(AudioOutputStream audioOutputStream)
    {
        AudioSource audioSource = GetComponent<AudioSource>();

        // Create audio source if needed.
        if (audioSource == null)
        {
            audioSource = gameObject.AddComponent<AudioSource>();
            audioSource.spatialize = false;
            audioSource.spatialBlend = 0;
        }

        // TODO: Do we want AudioClip's sample rate to match OPUS? That means Unity is left with doing any resampling. We might be able to do the resampling better ourselves.
        // TODO: We can probably specify a shorter clip length here since it's autogenerated now.
        if (_audioClip == null)
            _audioClip = AudioClip.Create("Normcore Audio Stream", 48000, 1, 48000, true, (float[] data) => { for (int i = 0; i < data.Length; i++) data[i] = 1.0f; });

        audioSource.enabled = true;
        audioSource.loop = true;
        audioSource.clip = _audioClip;
        audioSource.pitch = 1.0f;
        audioSource.spatializePostEffects = false;
        audioSource.Play();
    }
}

